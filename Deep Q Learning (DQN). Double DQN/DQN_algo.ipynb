{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwPGp-din1Ib",
        "outputId": "122b2984-0533-4a1c-85da-b6f5195333fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ufal.pybox2d\n",
            "  Downloading ufal.pybox2d-2.3.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ufal.pybox2d\n",
            "Successfully installed ufal.pybox2d-2.3.10.2\n"
          ]
        }
      ],
      "source": [
        "!pip install ufal.pybox2d"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "2ukBztwcn5kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DQN\n",
        "\n",
        "We implement the approximation structure $Q^\\theta$, initial parameters vector $\\theta$, probability of environment exploration $\\varepsilon = 1$.\n",
        "\n",
        "For each episode $k$ do:\n",
        "\n",
        "While episode not done:\n",
        "\n",
        "- Being in state $S_t$ we do action $A_t \\sim \\pi(\\cdot|S_t)$, where $\\pi = \\varepsilon\\text{-greedy}(Q^\\theta)$, receive reward $R_t$  move to state $S_{t+1}$. Save $(S_t,A_t,R_t,S_{t+1}) \\rightarrow Memory$\n",
        "\n",
        "\n",
        "- Take $\\{(s_i,a_i,r_i,s'_i)\\}_{i=1}^{n} \\leftarrow Memory$, obtain targets:\n",
        "\n",
        "$$\n",
        "y_i =\n",
        "\\left\\{\n",
        "\\begin{array}{ll}\n",
        "r_i, &\\text{ if } s'_i\\text{ -terminal state},\\\\[0.0cm]\n",
        " r_i + \\gamma \\max\\limits_{a'} Q^\\theta(s'_i,a'), &\\text{ otherwise}\n",
        "\\end{array}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "Loss function $Loss(\\theta) = \\frac{1}{n}\\sum\\limits_{i=1}^n \\big(y_i - Q^\\theta(s_i,a_i)\\big)^2$\n",
        "and upgrade the parameters vectors\n",
        "\n",
        "$$\n",
        "\\theta \\leftarrow \\theta - \\alpha \\nabla_\\theta Loss(\\theta)\n",
        "$$\n",
        "\n",
        "- Decrease $\\varepsilon$"
      ],
      "metadata": {
        "id": "7acYXUtFn81G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Qfunction(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        super().__init__()\n",
        "        self.linear_1 = nn.Linear(state_dim, 64)\n",
        "        self.linear_2 = nn.Linear(64, 64)\n",
        "        self.linear_3 = nn.Linear(64, action_dim)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, states):\n",
        "        hidden = self.linear_1(states)\n",
        "        hidden = self.activation(hidden)\n",
        "        hidden = self.linear_2(hidden)\n",
        "        hidden = self.activation(hidden)\n",
        "        actions = self.linear_3(hidden)\n",
        "        return actions"
      ],
      "metadata": {
        "id": "-P1KHjIuoAij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN:\n",
        "    def __init__(self, state_dim, action_dim, gamma=0.99, lr=1e-3, batch_size=64, epsilon_decrease=0.01, epilon_min=0.01):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.q_function = Qfunction(self.state_dim, self.action_dim)\n",
        "        self.gamma = gamma\n",
        "        self.batch_size = batch_size\n",
        "        self.epsilon = 1\n",
        "        self.epsilon_decrease = epsilon_decrease\n",
        "        self.epilon_min = epilon_min\n",
        "        self.memory = []\n",
        "        self.optimizer = torch.optim.Adam(self.q_function.parameters(), lr=lr)\n",
        "\n",
        "    def get_action(self, state):\n",
        "        q_values = self.q_function(torch.FloatTensor(state))\n",
        "        argmax_action = torch.argmax(q_values)\n",
        "        probs = self.epsilon * np.ones(self.action_dim) / self.action_dim\n",
        "        probs[argmax_action] += 1 - self.epsilon\n",
        "        action = np.random.choice(np.arange(self.action_dim), p=probs)\n",
        "        return action\n",
        "\n",
        "    def fit(self, state, action, reward, done, next_state):\n",
        "        self.memory.append([state, action, reward, int(done), next_state])\n",
        "\n",
        "        if len(self.memory) > self.batch_size:\n",
        "            batch = random.sample(self.memory, self.batch_size)\n",
        "            states, actions, rewards, dones, next_states = map(torch.tensor, list(zip(*batch)))\n",
        "\n",
        "            targets = rewards + self.gamma * (1 - dones) * torch.max(self.q_function(next_states), dim=1).values\n",
        "            q_values = self.q_function(states)[torch.arange(self.batch_size), actions]\n",
        "\n",
        "            loss = torch.mean((q_values - targets.detach()) ** 2)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            if self.epsilon > self.epilon_min:\n",
        "                self.epsilon -= self.epsilon_decrease"
      ],
      "metadata": {
        "id": "ZoZT4ZEAoCeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "rewards_DQN = []\n",
        "\n",
        "env = gym.make('LunarLander-v2')\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.n\n",
        "\n",
        "agent = DQN(state_dim, action_dim)\n",
        "\n",
        "episode_n = 500\n",
        "t_max = 500\n",
        "\n",
        "for episode in range(episode_n):\n",
        "    total_reward = 0\n",
        "\n",
        "    state = env.reset()\n",
        "    for t in range(t_max):\n",
        "        action = agent.get_action(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "        total_reward += reward\n",
        "\n",
        "        agent.fit(state, action, reward, done, next_state)\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "    rewards_DQN.append(total_reward)\n",
        "    print(f'episode: {episode}, total_reward: {total_reward}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9wsJr17oEiI",
        "outputId": "a43270d9-c15c-409d-bbdf-b53c43cb908b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode: 0, total_reward: -84.1259642937659\n",
            "episode: 1, total_reward: -491.2320308458567\n",
            "episode: 2, total_reward: -501.3555471175147\n",
            "episode: 3, total_reward: -379.44638760286585\n",
            "episode: 4, total_reward: -284.94163137576726\n",
            "episode: 5, total_reward: -246.88979556653837\n",
            "episode: 6, total_reward: -154.19232670360572\n",
            "episode: 7, total_reward: -33.35953973238743\n",
            "episode: 8, total_reward: -161.34901282150375\n",
            "episode: 9, total_reward: -42.261304297145784\n",
            "episode: 10, total_reward: -186.57785072914623\n",
            "episode: 11, total_reward: -120.78421633077963\n",
            "episode: 12, total_reward: -271.96141654871525\n",
            "episode: 13, total_reward: -393.1022819024783\n",
            "episode: 14, total_reward: -251.07657729052903\n",
            "episode: 15, total_reward: -84.8583695942867\n",
            "episode: 16, total_reward: -168.15288348226807\n",
            "episode: 17, total_reward: -138.1185697229489\n",
            "episode: 18, total_reward: 28.50779037452744\n",
            "episode: 19, total_reward: 23.93757505524393\n",
            "episode: 20, total_reward: -444.9791639014196\n",
            "episode: 21, total_reward: -146.15687582204558\n",
            "episode: 22, total_reward: -60.50560289984053\n",
            "episode: 23, total_reward: -27.735553967241856\n",
            "episode: 24, total_reward: -227.31014017640445\n",
            "episode: 25, total_reward: -148.38022693002074\n",
            "episode: 26, total_reward: -52.87633708455725\n",
            "episode: 27, total_reward: -66.34936851749636\n",
            "episode: 28, total_reward: -1.021830484231236\n",
            "episode: 29, total_reward: -27.765693460182653\n",
            "episode: 30, total_reward: -55.47220962053317\n",
            "episode: 31, total_reward: -57.073072270974045\n",
            "episode: 32, total_reward: -171.06118289729702\n",
            "episode: 33, total_reward: -105.78655713682753\n",
            "episode: 34, total_reward: -4.5895691899323765\n",
            "episode: 35, total_reward: -33.063921630703256\n",
            "episode: 36, total_reward: -7.045090275510295\n",
            "episode: 37, total_reward: 0.24894038958035036\n",
            "episode: 38, total_reward: -44.80762397368581\n",
            "episode: 39, total_reward: -36.83609220869175\n",
            "episode: 40, total_reward: -7.907781031547824\n",
            "episode: 41, total_reward: 26.13387751644877\n",
            "episode: 42, total_reward: -287.6405135044558\n",
            "episode: 43, total_reward: -14.534904772206913\n",
            "episode: 44, total_reward: -122.77665826912808\n",
            "episode: 45, total_reward: -96.93296008610665\n",
            "episode: 46, total_reward: -137.9653710977518\n",
            "episode: 47, total_reward: -113.90364476798618\n",
            "episode: 48, total_reward: -188.2071023672662\n",
            "episode: 49, total_reward: -76.84798259369707\n",
            "episode: 50, total_reward: -56.63489329175665\n",
            "episode: 51, total_reward: 5.2507152719093195\n",
            "episode: 52, total_reward: -9.115347709872196\n",
            "episode: 53, total_reward: -12.141645438745076\n",
            "episode: 54, total_reward: -38.93349976104338\n",
            "episode: 55, total_reward: -10.166004564399326\n",
            "episode: 56, total_reward: -10.48553325899036\n",
            "episode: 57, total_reward: 35.95353621411638\n",
            "episode: 58, total_reward: -20.16880217100508\n",
            "episode: 59, total_reward: -350.86994587370293\n",
            "episode: 60, total_reward: 1.7538555178557846\n",
            "episode: 61, total_reward: -94.62181741394201\n",
            "episode: 62, total_reward: -24.120574010252305\n",
            "episode: 63, total_reward: -32.89102715229538\n",
            "episode: 64, total_reward: -24.292365633008362\n",
            "episode: 65, total_reward: -114.96712932978721\n",
            "episode: 66, total_reward: -78.35377234161474\n",
            "episode: 67, total_reward: -8.945388493974203\n",
            "episode: 68, total_reward: -6.112065539720671\n",
            "episode: 69, total_reward: -21.510117860967316\n",
            "episode: 70, total_reward: 5.593155899745176\n",
            "episode: 71, total_reward: -14.149331193268175\n",
            "episode: 72, total_reward: -10.02891735884574\n",
            "episode: 73, total_reward: -278.7284376975375\n",
            "episode: 74, total_reward: -27.40781381444421\n",
            "episode: 75, total_reward: 28.083379423485763\n",
            "episode: 76, total_reward: 8.204618633980166\n",
            "episode: 77, total_reward: 54.3617139490804\n",
            "episode: 78, total_reward: 20.74182911442036\n",
            "episode: 79, total_reward: 47.82682272499011\n",
            "episode: 80, total_reward: -178.882714769402\n",
            "episode: 81, total_reward: 16.73384484466808\n",
            "episode: 82, total_reward: 54.936933388842704\n",
            "episode: 83, total_reward: 39.446622393858945\n",
            "episode: 84, total_reward: 1.4000441943118593\n",
            "episode: 85, total_reward: 9.144547020314423\n",
            "episode: 86, total_reward: 15.306713898190347\n",
            "episode: 87, total_reward: 68.8504946295259\n",
            "episode: 88, total_reward: 64.83907692676571\n",
            "episode: 89, total_reward: 20.357088633390934\n",
            "episode: 90, total_reward: 29.048456470364428\n",
            "episode: 91, total_reward: 77.21052839128062\n",
            "episode: 92, total_reward: 28.11446498823681\n",
            "episode: 93, total_reward: 61.75204170807963\n",
            "episode: 94, total_reward: 73.06004249414629\n",
            "episode: 95, total_reward: 90.5939793988062\n",
            "episode: 96, total_reward: 52.948510428803345\n",
            "episode: 97, total_reward: 51.97141819986665\n",
            "episode: 98, total_reward: 3.5638892956350894\n",
            "episode: 99, total_reward: 37.11182669159511\n",
            "episode: 100, total_reward: 33.165881483792745\n",
            "episode: 101, total_reward: 92.3229149244321\n",
            "episode: 102, total_reward: 19.725296219797094\n",
            "episode: 103, total_reward: 55.49883696950866\n",
            "episode: 104, total_reward: -11.174196482869064\n",
            "episode: 105, total_reward: 21.719861990378817\n",
            "episode: 106, total_reward: 89.5520878172568\n",
            "episode: 107, total_reward: 47.93529513247232\n",
            "episode: 108, total_reward: 46.007589529740066\n",
            "episode: 109, total_reward: 75.58520812804134\n",
            "episode: 110, total_reward: 29.917382323141698\n",
            "episode: 111, total_reward: 73.98956557805373\n",
            "episode: 112, total_reward: 17.10375959245493\n",
            "episode: 113, total_reward: 37.52695289927473\n",
            "episode: 114, total_reward: 41.192589554031414\n",
            "episode: 115, total_reward: 39.58557965730983\n",
            "episode: 116, total_reward: 29.536205850913472\n",
            "episode: 117, total_reward: 75.83238336241376\n",
            "episode: 118, total_reward: 73.37824002242515\n",
            "episode: 119, total_reward: 82.20755072088576\n",
            "episode: 120, total_reward: 28.246160412519362\n",
            "episode: 121, total_reward: 2.1818323308077505\n",
            "episode: 122, total_reward: 55.399001633627876\n",
            "episode: 123, total_reward: 32.30740713942834\n",
            "episode: 124, total_reward: 27.459822241692194\n",
            "episode: 125, total_reward: 76.18877351844333\n",
            "episode: 126, total_reward: 54.151576184346226\n",
            "episode: 127, total_reward: 24.021765905859212\n",
            "episode: 128, total_reward: 79.9033338915123\n",
            "episode: 129, total_reward: 48.210658410935416\n",
            "episode: 130, total_reward: 32.45752146414569\n",
            "episode: 131, total_reward: 83.46223013514816\n",
            "episode: 132, total_reward: 43.490550199034324\n",
            "episode: 133, total_reward: 69.36696187724931\n",
            "episode: 134, total_reward: 71.29957430180548\n",
            "episode: 135, total_reward: 30.944476687816092\n",
            "episode: 136, total_reward: 75.81503669255304\n",
            "episode: 137, total_reward: 71.51640560505054\n",
            "episode: 138, total_reward: 107.21666193485352\n",
            "episode: 139, total_reward: 44.59364929461785\n",
            "episode: 140, total_reward: 76.52056174291555\n",
            "episode: 141, total_reward: 57.136651964165175\n",
            "episode: 142, total_reward: 55.48402741973552\n",
            "episode: 143, total_reward: 27.767197193868355\n",
            "episode: 144, total_reward: 29.23401277724934\n",
            "episode: 145, total_reward: -115.82672675376904\n",
            "episode: 146, total_reward: 74.69920424993686\n",
            "episode: 147, total_reward: 97.62183658901448\n",
            "episode: 148, total_reward: 63.30365330324557\n",
            "episode: 149, total_reward: 31.70536674788811\n",
            "episode: 150, total_reward: -65.36009279188185\n",
            "episode: 151, total_reward: 214.08638316131425\n",
            "episode: 152, total_reward: 84.38601884287273\n",
            "episode: 153, total_reward: -27.94851887524289\n",
            "episode: 154, total_reward: 34.49739401785365\n",
            "episode: 155, total_reward: 87.06214063709666\n",
            "episode: 156, total_reward: 60.111888209002124\n",
            "episode: 157, total_reward: 72.83362838176663\n",
            "episode: 158, total_reward: -31.18617853880327\n",
            "episode: 159, total_reward: 85.38897751614543\n",
            "episode: 160, total_reward: 86.42803502557713\n",
            "episode: 161, total_reward: 61.13595888441929\n",
            "episode: 162, total_reward: 60.30252399120718\n",
            "episode: 163, total_reward: 32.658495043974916\n",
            "episode: 164, total_reward: 59.863333253975796\n",
            "episode: 165, total_reward: 14.630517338097436\n",
            "episode: 166, total_reward: 19.436949656014953\n",
            "episode: 167, total_reward: 1.4539010909786523\n",
            "episode: 168, total_reward: 56.513874721016066\n",
            "episode: 169, total_reward: 93.59541122643432\n",
            "episode: 170, total_reward: 39.25984869001336\n",
            "episode: 171, total_reward: 60.63356685108883\n",
            "episode: 172, total_reward: 63.10796177817911\n",
            "episode: 173, total_reward: -228.30628113312\n",
            "episode: 174, total_reward: -14.281150075379548\n",
            "episode: 175, total_reward: 46.815143204445704\n",
            "episode: 176, total_reward: 10.518040245678339\n",
            "episode: 177, total_reward: -83.57548986766166\n",
            "episode: 178, total_reward: 78.11493260413677\n",
            "episode: 179, total_reward: 46.497653972759906\n",
            "episode: 180, total_reward: -9.055236358432495\n",
            "episode: 181, total_reward: 231.0858479404625\n",
            "episode: 182, total_reward: -34.17606214102109\n",
            "episode: 183, total_reward: 34.88279116924212\n",
            "episode: 184, total_reward: 55.45260649225622\n",
            "episode: 185, total_reward: 39.69150698975683\n",
            "episode: 186, total_reward: 47.50999850084908\n",
            "episode: 187, total_reward: 56.90593796116202\n",
            "episode: 188, total_reward: 62.36374129111002\n",
            "episode: 189, total_reward: 58.44658554897304\n",
            "episode: 190, total_reward: 39.47686537019746\n",
            "episode: 191, total_reward: 86.71326209316061\n",
            "episode: 192, total_reward: 65.43830969212009\n",
            "episode: 193, total_reward: 52.49567868481663\n",
            "episode: 194, total_reward: 63.179396594895636\n",
            "episode: 195, total_reward: 69.23670315380376\n",
            "episode: 196, total_reward: 53.82033641177646\n",
            "episode: 197, total_reward: 72.59025354284256\n",
            "episode: 198, total_reward: 84.14909813757745\n",
            "episode: 199, total_reward: 100.17388625127802\n",
            "episode: 200, total_reward: 12.839846364507412\n",
            "episode: 201, total_reward: -6.369780998101645\n",
            "episode: 202, total_reward: 91.62719325707869\n",
            "episode: 203, total_reward: 226.41635835254755\n",
            "episode: 204, total_reward: 48.16596239649698\n",
            "episode: 205, total_reward: 187.05876582135156\n",
            "episode: 206, total_reward: 61.34981049034537\n",
            "episode: 207, total_reward: 134.66641780660464\n",
            "episode: 208, total_reward: 16.60491850085767\n",
            "episode: 209, total_reward: 15.602627045936266\n",
            "episode: 210, total_reward: 54.3187320226024\n",
            "episode: 211, total_reward: 32.66290179590696\n",
            "episode: 212, total_reward: 62.653881714799674\n",
            "episode: 213, total_reward: 92.81059678868894\n",
            "episode: 214, total_reward: 37.776028686452946\n",
            "episode: 215, total_reward: 37.95017907836001\n",
            "episode: 216, total_reward: 87.28846402110722\n",
            "episode: 217, total_reward: -34.88693739419317\n",
            "episode: 218, total_reward: 112.96444304009643\n",
            "episode: 219, total_reward: 45.91559774171832\n",
            "episode: 220, total_reward: 102.01429528475352\n",
            "episode: 221, total_reward: 31.766302367966233\n",
            "episode: 222, total_reward: -47.9148655746379\n",
            "episode: 223, total_reward: 9.599188714638103\n",
            "episode: 224, total_reward: 41.30813158508593\n",
            "episode: 225, total_reward: 80.21975609884389\n",
            "episode: 226, total_reward: -21.219301583880466\n",
            "episode: 227, total_reward: -5.461351889417145\n",
            "episode: 228, total_reward: 28.75071231837139\n",
            "episode: 229, total_reward: 78.43862707147343\n",
            "episode: 230, total_reward: 189.42477621165804\n",
            "episode: 231, total_reward: 99.66574470685849\n",
            "episode: 232, total_reward: 89.1134924666101\n",
            "episode: 233, total_reward: 71.7442738650692\n",
            "episode: 234, total_reward: 60.10876955344125\n",
            "episode: 235, total_reward: -53.86468889064699\n",
            "episode: 236, total_reward: 100.86110700287249\n",
            "episode: 237, total_reward: 73.16907651477102\n",
            "episode: 238, total_reward: 75.7073191496168\n",
            "episode: 239, total_reward: 36.56734798676366\n",
            "episode: 240, total_reward: 141.37429550996762\n",
            "episode: 241, total_reward: 17.21404278557068\n",
            "episode: 242, total_reward: 15.972423773378242\n",
            "episode: 243, total_reward: 102.85251022281605\n",
            "episode: 244, total_reward: 72.60011798180548\n",
            "episode: 245, total_reward: 57.130460722357306\n",
            "episode: 246, total_reward: 240.67680909921762\n",
            "episode: 247, total_reward: 34.562554275352\n",
            "episode: 248, total_reward: 85.6813494070271\n",
            "episode: 249, total_reward: 78.34903474856439\n",
            "episode: 250, total_reward: 26.839693377575728\n",
            "episode: 251, total_reward: 47.99212161613741\n",
            "episode: 252, total_reward: 77.94779853229322\n",
            "episode: 253, total_reward: 58.327745521693444\n",
            "episode: 254, total_reward: 46.99641158779397\n",
            "episode: 255, total_reward: -2.4132782659330303\n",
            "episode: 256, total_reward: 25.46778503655505\n",
            "episode: 257, total_reward: 258.03357843981973\n",
            "episode: 258, total_reward: 264.62834616030057\n",
            "episode: 259, total_reward: 14.44475401852425\n",
            "episode: 260, total_reward: 279.3005964785107\n",
            "episode: 261, total_reward: 158.65557263591603\n",
            "episode: 262, total_reward: 219.28259113082646\n",
            "episode: 263, total_reward: 93.16436810352413\n",
            "episode: 264, total_reward: 193.1811062716866\n",
            "episode: 265, total_reward: -50.46166012966967\n",
            "episode: 266, total_reward: 71.02565522789425\n",
            "episode: 267, total_reward: 61.14247646891795\n",
            "episode: 268, total_reward: 280.1078111598776\n",
            "episode: 269, total_reward: 99.14059181464542\n",
            "episode: 270, total_reward: -79.50397190760233\n",
            "episode: 271, total_reward: 23.783921338226644\n",
            "episode: 272, total_reward: 67.23746415195639\n",
            "episode: 273, total_reward: 36.63148606390578\n",
            "episode: 274, total_reward: 118.71443925924848\n",
            "episode: 275, total_reward: 160.48157782423766\n",
            "episode: 276, total_reward: 0.7562339697523441\n",
            "episode: 277, total_reward: 33.03886803585945\n",
            "episode: 278, total_reward: 34.682201009995154\n",
            "episode: 279, total_reward: 223.11762116428432\n",
            "episode: 280, total_reward: 91.8545218857637\n",
            "episode: 281, total_reward: 41.19570703560469\n",
            "episode: 282, total_reward: 29.755042320268583\n",
            "episode: 283, total_reward: 273.5059159924372\n",
            "episode: 284, total_reward: 56.904463861377955\n",
            "episode: 285, total_reward: -18.085501975615855\n",
            "episode: 286, total_reward: 38.27617191122658\n",
            "episode: 287, total_reward: 74.55669470362812\n",
            "episode: 288, total_reward: -81.41808274384643\n",
            "episode: 289, total_reward: 76.33021496461801\n",
            "episode: 290, total_reward: -16.39035285820647\n",
            "episode: 291, total_reward: 50.736465443365894\n",
            "episode: 292, total_reward: 280.29352374812356\n",
            "episode: 293, total_reward: -27.41730231615032\n",
            "episode: 294, total_reward: 15.18913822670494\n",
            "episode: 295, total_reward: -91.52761034487364\n",
            "episode: 296, total_reward: -8.436726407848624\n",
            "episode: 297, total_reward: 257.457130049443\n",
            "episode: 298, total_reward: 249.94220519651273\n",
            "episode: 299, total_reward: -15.83508708030702\n",
            "episode: 300, total_reward: 53.15579587790451\n",
            "episode: 301, total_reward: 32.81398459646954\n",
            "episode: 302, total_reward: 70.21123978408735\n",
            "episode: 303, total_reward: 164.89126650256821\n",
            "episode: 304, total_reward: 164.55777960436157\n",
            "episode: 305, total_reward: 26.632728591851304\n",
            "episode: 306, total_reward: -21.05825755600233\n",
            "episode: 307, total_reward: 279.62016962052803\n",
            "episode: 308, total_reward: 23.901493782744165\n",
            "episode: 309, total_reward: 275.8015320912593\n",
            "episode: 310, total_reward: 58.008443909814986\n",
            "episode: 311, total_reward: 26.2367265591178\n",
            "episode: 312, total_reward: 268.0997174608293\n",
            "episode: 313, total_reward: -1.8152434919139182\n",
            "episode: 314, total_reward: 272.04798593091846\n",
            "episode: 315, total_reward: 72.51962703326532\n",
            "episode: 316, total_reward: -6.716080363554241\n",
            "episode: 317, total_reward: 277.45385443391405\n",
            "episode: 318, total_reward: 98.55960669880983\n",
            "episode: 319, total_reward: 7.853401057082884\n",
            "episode: 320, total_reward: 41.444664780955826\n",
            "episode: 321, total_reward: 74.30420227041907\n",
            "episode: 322, total_reward: 229.7087079344678\n",
            "episode: 323, total_reward: 94.6819637749564\n",
            "episode: 324, total_reward: 141.25185869248656\n",
            "episode: 325, total_reward: 206.71526681800333\n",
            "episode: 326, total_reward: 262.48639183704574\n",
            "episode: 327, total_reward: -76.26328409997427\n",
            "episode: 328, total_reward: 52.29407905707623\n",
            "episode: 329, total_reward: 200.4142290743075\n",
            "episode: 330, total_reward: 4.834038333195806\n",
            "episode: 331, total_reward: 260.6312276036207\n",
            "episode: 332, total_reward: -32.22042992790283\n",
            "episode: 333, total_reward: 35.69695816233386\n",
            "episode: 334, total_reward: 258.65742915374335\n",
            "episode: 335, total_reward: 26.230603810493015\n",
            "episode: 336, total_reward: 45.14131405037665\n",
            "episode: 337, total_reward: 34.32433184861309\n",
            "episode: 338, total_reward: 40.78783675040266\n",
            "episode: 339, total_reward: 251.2461154754331\n",
            "episode: 340, total_reward: 236.7333877342009\n",
            "episode: 341, total_reward: 24.361871966661347\n",
            "episode: 342, total_reward: 93.84464418106246\n",
            "episode: 343, total_reward: 37.00363096631001\n",
            "episode: 344, total_reward: 52.9539121377546\n",
            "episode: 345, total_reward: -8.832109719994605\n",
            "episode: 346, total_reward: -66.65308413292347\n",
            "episode: 347, total_reward: 275.0993972113773\n",
            "episode: 348, total_reward: -219.8956609088337\n",
            "episode: 349, total_reward: 225.95131549526502\n",
            "episode: 350, total_reward: 20.47805503296193\n",
            "episode: 351, total_reward: -42.57934295134196\n",
            "episode: 352, total_reward: 25.02710754309102\n",
            "episode: 353, total_reward: 111.9187302226382\n",
            "episode: 354, total_reward: 213.44027703752624\n",
            "episode: 355, total_reward: 44.804537619762584\n",
            "episode: 356, total_reward: -32.958774936587226\n",
            "episode: 357, total_reward: 64.69976829140936\n",
            "episode: 358, total_reward: -43.55832776758426\n",
            "episode: 359, total_reward: 239.46664712643494\n",
            "episode: 360, total_reward: -200.84853754086873\n",
            "episode: 361, total_reward: 70.59677826814843\n",
            "episode: 362, total_reward: -5.911511732900578\n",
            "episode: 363, total_reward: -1.232725375947185\n",
            "episode: 364, total_reward: 14.513778641487447\n",
            "episode: 365, total_reward: 20.147132288472758\n",
            "episode: 366, total_reward: 22.294772470610873\n",
            "episode: 367, total_reward: 63.80041795487966\n",
            "episode: 368, total_reward: 159.77642944648017\n",
            "episode: 369, total_reward: 65.7179053379211\n",
            "episode: 370, total_reward: 55.79492884914691\n",
            "episode: 371, total_reward: 55.70509841685123\n",
            "episode: 372, total_reward: 4.796968055874654\n",
            "episode: 373, total_reward: 248.92772197192014\n",
            "episode: 374, total_reward: 260.82484847115603\n",
            "episode: 375, total_reward: 14.640192172951817\n",
            "episode: 376, total_reward: -19.23648072082844\n",
            "episode: 377, total_reward: 87.52890907910366\n",
            "episode: 378, total_reward: 96.52555964051608\n",
            "episode: 379, total_reward: -62.12439068705403\n",
            "episode: 380, total_reward: 197.56236071918985\n",
            "episode: 381, total_reward: -28.71964745340115\n",
            "episode: 382, total_reward: 14.582982306474314\n",
            "episode: 383, total_reward: 9.985710974198675\n",
            "episode: 384, total_reward: -159.49216446276066\n",
            "episode: 385, total_reward: 242.79265359211402\n",
            "episode: 386, total_reward: 52.32481957031824\n",
            "episode: 387, total_reward: -295.94124092840593\n",
            "episode: 388, total_reward: 50.50898733709495\n",
            "episode: 389, total_reward: 68.4088716159743\n",
            "episode: 390, total_reward: 0.3131112892538348\n",
            "episode: 391, total_reward: 110.86298098431952\n",
            "episode: 392, total_reward: 7.9597237166292\n",
            "episode: 393, total_reward: 236.39082657242906\n",
            "episode: 394, total_reward: 69.98552436138739\n",
            "episode: 395, total_reward: 90.65193216627856\n",
            "episode: 396, total_reward: 75.43957842240654\n",
            "episode: 397, total_reward: -7.47933898986267\n",
            "episode: 398, total_reward: 51.06147717921287\n",
            "episode: 399, total_reward: 71.32579105835546\n",
            "episode: 400, total_reward: 209.80978635143893\n",
            "episode: 401, total_reward: 241.28245294192288\n",
            "episode: 402, total_reward: 84.44111563506851\n",
            "episode: 403, total_reward: 65.61561881396304\n",
            "episode: 404, total_reward: -52.81838131958742\n",
            "episode: 405, total_reward: 154.37120524842067\n",
            "episode: 406, total_reward: 244.2738377587091\n",
            "episode: 407, total_reward: 213.03895352175056\n",
            "episode: 408, total_reward: 34.49722484460135\n",
            "episode: 409, total_reward: 220.6280323214889\n",
            "episode: 410, total_reward: 243.2427277182762\n",
            "episode: 411, total_reward: 174.2035338567939\n",
            "episode: 412, total_reward: -83.13796747007437\n",
            "episode: 413, total_reward: 33.8020681518959\n",
            "episode: 414, total_reward: 246.11952014182862\n",
            "episode: 415, total_reward: -177.4146482346717\n",
            "episode: 416, total_reward: 224.78608639692948\n",
            "episode: 417, total_reward: -102.62602802643241\n",
            "episode: 418, total_reward: -82.7927862342814\n",
            "episode: 419, total_reward: -133.54042568090009\n",
            "episode: 420, total_reward: 31.522717664332138\n",
            "episode: 421, total_reward: 226.59263331114403\n",
            "episode: 422, total_reward: -58.93565718653723\n",
            "episode: 423, total_reward: 227.21697280909143\n",
            "episode: 424, total_reward: 259.5167657445705\n",
            "episode: 425, total_reward: -145.5528495988367\n",
            "episode: 426, total_reward: 233.92483258358\n",
            "episode: 427, total_reward: 217.4339564590181\n",
            "episode: 428, total_reward: 117.49350039476532\n",
            "episode: 429, total_reward: 222.8268076238617\n",
            "episode: 430, total_reward: 127.15594274988271\n",
            "episode: 431, total_reward: 15.545711125030635\n",
            "episode: 432, total_reward: -183.104879186441\n",
            "episode: 433, total_reward: 124.98384516704151\n",
            "episode: 434, total_reward: 236.24641369644635\n",
            "episode: 435, total_reward: 187.70321637004085\n",
            "episode: 436, total_reward: 257.68713143959525\n",
            "episode: 437, total_reward: 219.72760359421733\n",
            "episode: 438, total_reward: 258.82767623903624\n",
            "episode: 439, total_reward: 255.86027165223447\n",
            "episode: 440, total_reward: 267.753428203896\n",
            "episode: 441, total_reward: 82.66650241180609\n",
            "episode: 442, total_reward: 287.53376137218515\n",
            "episode: 443, total_reward: 182.37709402201608\n",
            "episode: 444, total_reward: 176.8197479990916\n",
            "episode: 445, total_reward: 61.99435851222822\n",
            "episode: 446, total_reward: 61.74049337349028\n",
            "episode: 447, total_reward: -50.74701675816857\n",
            "episode: 448, total_reward: 228.60378275957584\n",
            "episode: 449, total_reward: 226.027458403112\n",
            "episode: 450, total_reward: 209.64508251888907\n",
            "episode: 451, total_reward: 273.6738682110986\n",
            "episode: 452, total_reward: 138.71708350316564\n",
            "episode: 453, total_reward: 281.4892195812654\n",
            "episode: 454, total_reward: 210.61089425716648\n",
            "episode: 455, total_reward: 225.6033778060668\n",
            "episode: 456, total_reward: 80.02418491250884\n",
            "episode: 457, total_reward: 259.83168388177603\n",
            "episode: 458, total_reward: 49.587854074818736\n",
            "episode: 459, total_reward: 234.28616733789468\n",
            "episode: 460, total_reward: 47.79944733984774\n",
            "episode: 461, total_reward: 233.81701128339705\n",
            "episode: 462, total_reward: 220.59383577636132\n",
            "episode: 463, total_reward: 108.85334357557817\n",
            "episode: 464, total_reward: 8.479570923852926\n",
            "episode: 465, total_reward: -162.66294942797265\n",
            "episode: 466, total_reward: 255.2646728511576\n",
            "episode: 467, total_reward: 249.53887107419828\n",
            "episode: 468, total_reward: 226.68435004711392\n",
            "episode: 469, total_reward: 119.97551202241782\n",
            "episode: 470, total_reward: 70.97205031569378\n",
            "episode: 471, total_reward: 243.02883968646563\n",
            "episode: 472, total_reward: 247.33657560691657\n",
            "episode: 473, total_reward: 118.57403955096794\n",
            "episode: 474, total_reward: 200.85547077566258\n",
            "episode: 475, total_reward: 85.90700485201783\n",
            "episode: 476, total_reward: 233.30348714736002\n",
            "episode: 477, total_reward: 73.36689841714848\n",
            "episode: 478, total_reward: -35.17103717903123\n",
            "episode: 479, total_reward: 93.99193131511339\n",
            "episode: 480, total_reward: 237.2766477629964\n",
            "episode: 481, total_reward: -60.954560613489434\n",
            "episode: 482, total_reward: 234.89250076869007\n",
            "episode: 483, total_reward: 240.8825058622974\n",
            "episode: 484, total_reward: 84.56926467844627\n",
            "episode: 485, total_reward: 102.18437033075324\n",
            "episode: 486, total_reward: 118.37802613423696\n",
            "episode: 487, total_reward: -83.33751167776327\n",
            "episode: 488, total_reward: 262.83438716319347\n",
            "episode: 489, total_reward: 234.75744836764855\n",
            "episode: 490, total_reward: -95.09579710538745\n",
            "episode: 491, total_reward: 218.76734277515078\n",
            "episode: 492, total_reward: 263.611042671804\n",
            "episode: 493, total_reward: 261.88264633549124\n",
            "episode: 494, total_reward: 265.5858859861359\n",
            "episode: 495, total_reward: 35.98327258948434\n",
            "episode: 496, total_reward: 243.53116483698327\n",
            "episode: 497, total_reward: 130.33887000485635\n",
            "episode: 498, total_reward: -106.98236446983051\n",
            "episode: 499, total_reward: 132.14342391820145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.line(rewards_DQN, title='Rewards graph DQN').update_layout(xaxis_title=\"Iteration\", yaxis_title=\"Reward\")\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "EhRkOU0NygPs",
        "outputId": "ccc0948c-8338-4940-fae0-03ab997d1ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"29e17f4a-bc82-4da1-aca1-2b1466c405a9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"29e17f4a-bc82-4da1-aca1-2b1466c405a9\")) {                    Plotly.newPlot(                        \"29e17f4a-bc82-4da1-aca1-2b1466c405a9\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499],\"xaxis\":\"x\",\"y\":[-84.1259642937659,-491.2320308458567,-501.3555471175147,-379.44638760286585,-284.94163137576726,-246.88979556653837,-154.19232670360572,-33.35953973238743,-161.34901282150375,-42.261304297145784,-186.57785072914623,-120.78421633077963,-271.96141654871525,-393.1022819024783,-251.07657729052903,-84.8583695942867,-168.15288348226807,-138.1185697229489,28.50779037452744,23.93757505524393,-444.9791639014196,-146.15687582204558,-60.50560289984053,-27.735553967241856,-227.31014017640445,-148.38022693002074,-52.87633708455725,-66.34936851749636,-1.021830484231236,-27.765693460182653,-55.47220962053317,-57.073072270974045,-171.06118289729702,-105.78655713682753,-4.5895691899323765,-33.063921630703256,-7.045090275510295,0.24894038958035036,-44.80762397368581,-36.83609220869175,-7.907781031547824,26.13387751644877,-287.6405135044558,-14.534904772206913,-122.77665826912808,-96.93296008610665,-137.9653710977518,-113.90364476798618,-188.2071023672662,-76.84798259369707,-56.63489329175665,5.2507152719093195,-9.115347709872196,-12.141645438745076,-38.93349976104338,-10.166004564399326,-10.48553325899036,35.95353621411638,-20.16880217100508,-350.86994587370293,1.7538555178557846,-94.62181741394201,-24.120574010252305,-32.89102715229538,-24.292365633008362,-114.96712932978721,-78.35377234161474,-8.945388493974203,-6.112065539720671,-21.510117860967316,5.593155899745176,-14.149331193268175,-10.02891735884574,-278.7284376975375,-27.40781381444421,28.083379423485763,8.204618633980166,54.3617139490804,20.74182911442036,47.82682272499011,-178.882714769402,16.73384484466808,54.936933388842704,39.446622393858945,1.4000441943118593,9.144547020314423,15.306713898190347,68.8504946295259,64.83907692676571,20.357088633390934,29.048456470364428,77.21052839128062,28.11446498823681,61.75204170807963,73.06004249414629,90.5939793988062,52.948510428803345,51.97141819986665,3.5638892956350894,37.11182669159511,33.165881483792745,92.3229149244321,19.725296219797094,55.49883696950866,-11.174196482869064,21.719861990378817,89.5520878172568,47.93529513247232,46.007589529740066,75.58520812804134,29.917382323141698,73.98956557805373,17.10375959245493,37.52695289927473,41.192589554031414,39.58557965730983,29.536205850913472,75.83238336241376,73.37824002242515,82.20755072088576,28.246160412519362,2.1818323308077505,55.399001633627876,32.30740713942834,27.459822241692194,76.18877351844333,54.151576184346226,24.021765905859212,79.9033338915123,48.210658410935416,32.45752146414569,83.46223013514816,43.490550199034324,69.36696187724931,71.29957430180548,30.944476687816092,75.81503669255304,71.51640560505054,107.21666193485352,44.59364929461785,76.52056174291555,57.136651964165175,55.48402741973552,27.767197193868355,29.23401277724934,-115.82672675376904,74.69920424993686,97.62183658901448,63.30365330324557,31.70536674788811,-65.36009279188185,214.08638316131425,84.38601884287273,-27.94851887524289,34.49739401785365,87.06214063709666,60.111888209002124,72.83362838176663,-31.18617853880327,85.38897751614543,86.42803502557713,61.13595888441929,60.30252399120718,32.658495043974916,59.863333253975796,14.630517338097436,19.436949656014953,1.4539010909786523,56.513874721016066,93.59541122643432,39.25984869001336,60.63356685108883,63.10796177817911,-228.30628113312,-14.281150075379548,46.815143204445704,10.518040245678339,-83.57548986766166,78.11493260413677,46.497653972759906,-9.055236358432495,231.0858479404625,-34.17606214102109,34.88279116924212,55.45260649225622,39.69150698975683,47.50999850084908,56.90593796116202,62.36374129111002,58.44658554897304,39.47686537019746,86.71326209316061,65.43830969212009,52.49567868481663,63.179396594895636,69.23670315380376,53.82033641177646,72.59025354284256,84.14909813757745,100.17388625127802,12.839846364507412,-6.369780998101645,91.62719325707869,226.41635835254755,48.16596239649698,187.05876582135156,61.34981049034537,134.66641780660464,16.60491850085767,15.602627045936266,54.3187320226024,32.66290179590696,62.653881714799674,92.81059678868894,37.776028686452946,37.95017907836001,87.28846402110722,-34.88693739419317,112.96444304009643,45.91559774171832,102.01429528475352,31.766302367966233,-47.9148655746379,9.599188714638103,41.30813158508593,80.21975609884389,-21.219301583880466,-5.461351889417145,28.75071231837139,78.43862707147343,189.42477621165804,99.66574470685849,89.1134924666101,71.7442738650692,60.10876955344125,-53.86468889064699,100.86110700287249,73.16907651477102,75.7073191496168,36.56734798676366,141.37429550996762,17.21404278557068,15.972423773378242,102.85251022281605,72.60011798180548,57.130460722357306,240.67680909921762,34.562554275352,85.6813494070271,78.34903474856439,26.839693377575728,47.99212161613741,77.94779853229322,58.327745521693444,46.99641158779397,-2.4132782659330303,25.46778503655505,258.03357843981973,264.62834616030057,14.44475401852425,279.3005964785107,158.65557263591603,219.28259113082646,93.16436810352413,193.1811062716866,-50.46166012966967,71.02565522789425,61.14247646891795,280.1078111598776,99.14059181464542,-79.50397190760233,23.783921338226644,67.23746415195639,36.63148606390578,118.71443925924848,160.48157782423766,0.7562339697523441,33.03886803585945,34.682201009995154,223.11762116428432,91.8545218857637,41.19570703560469,29.755042320268583,273.5059159924372,56.904463861377955,-18.085501975615855,38.27617191122658,74.55669470362812,-81.41808274384643,76.33021496461801,-16.39035285820647,50.736465443365894,280.29352374812356,-27.41730231615032,15.18913822670494,-91.52761034487364,-8.436726407848624,257.457130049443,249.94220519651273,-15.83508708030702,53.15579587790451,32.81398459646954,70.21123978408735,164.89126650256821,164.55777960436157,26.632728591851304,-21.05825755600233,279.62016962052803,23.901493782744165,275.8015320912593,58.008443909814986,26.2367265591178,268.0997174608293,-1.8152434919139182,272.04798593091846,72.51962703326532,-6.716080363554241,277.45385443391405,98.55960669880983,7.853401057082884,41.444664780955826,74.30420227041907,229.7087079344678,94.6819637749564,141.25185869248656,206.71526681800333,262.48639183704574,-76.26328409997427,52.29407905707623,200.4142290743075,4.834038333195806,260.6312276036207,-32.22042992790283,35.69695816233386,258.65742915374335,26.230603810493015,45.14131405037665,34.32433184861309,40.78783675040266,251.2461154754331,236.7333877342009,24.361871966661347,93.84464418106246,37.00363096631001,52.9539121377546,-8.832109719994605,-66.65308413292347,275.0993972113773,-219.8956609088337,225.95131549526502,20.47805503296193,-42.57934295134196,25.02710754309102,111.9187302226382,213.44027703752624,44.804537619762584,-32.958774936587226,64.69976829140936,-43.55832776758426,239.46664712643494,-200.84853754086873,70.59677826814843,-5.911511732900578,-1.232725375947185,14.513778641487447,20.147132288472758,22.294772470610873,63.80041795487966,159.77642944648017,65.7179053379211,55.79492884914691,55.70509841685123,4.796968055874654,248.92772197192014,260.82484847115603,14.640192172951817,-19.23648072082844,87.52890907910366,96.52555964051608,-62.12439068705403,197.56236071918985,-28.71964745340115,14.582982306474314,9.985710974198675,-159.49216446276066,242.79265359211402,52.32481957031824,-295.94124092840593,50.50898733709495,68.4088716159743,0.3131112892538348,110.86298098431952,7.9597237166292,236.39082657242906,69.98552436138739,90.65193216627856,75.43957842240654,-7.47933898986267,51.06147717921287,71.32579105835546,209.80978635143893,241.28245294192288,84.44111563506851,65.61561881396304,-52.81838131958742,154.37120524842067,244.2738377587091,213.03895352175056,34.49722484460135,220.6280323214889,243.2427277182762,174.2035338567939,-83.13796747007437,33.8020681518959,246.11952014182862,-177.4146482346717,224.78608639692948,-102.62602802643241,-82.7927862342814,-133.54042568090009,31.522717664332138,226.59263331114403,-58.93565718653723,227.21697280909143,259.5167657445705,-145.5528495988367,233.92483258358,217.4339564590181,117.49350039476532,222.8268076238617,127.15594274988271,15.545711125030635,-183.104879186441,124.98384516704151,236.24641369644635,187.70321637004085,257.68713143959525,219.72760359421733,258.82767623903624,255.86027165223447,267.753428203896,82.66650241180609,287.53376137218515,182.37709402201608,176.8197479990916,61.99435851222822,61.74049337349028,-50.74701675816857,228.60378275957584,226.027458403112,209.64508251888907,273.6738682110986,138.71708350316564,281.4892195812654,210.61089425716648,225.6033778060668,80.02418491250884,259.83168388177603,49.587854074818736,234.28616733789468,47.79944733984774,233.81701128339705,220.59383577636132,108.85334357557817,8.479570923852926,-162.66294942797265,255.2646728511576,249.53887107419828,226.68435004711392,119.97551202241782,70.97205031569378,243.02883968646563,247.33657560691657,118.57403955096794,200.85547077566258,85.90700485201783,233.30348714736002,73.36689841714848,-35.17103717903123,93.99193131511339,237.2766477629964,-60.954560613489434,234.89250076869007,240.8825058622974,84.56926467844627,102.18437033075324,118.37802613423696,-83.33751167776327,262.83438716319347,234.75744836764855,-95.09579710538745,218.76734277515078,263.611042671804,261.88264633549124,265.5858859861359,35.98327258948434,243.53116483698327,130.33887000485635,-106.98236446983051,132.14342391820145],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Iteration\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Reward\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Rewards graph DQN\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('29e17f4a-bc82-4da1-aca1-2b1466c405a9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uKscne2Czarn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}